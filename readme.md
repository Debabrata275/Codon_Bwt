# Codon Usage Tool (Codon + BWT)

A machine learning-based codon recommendation and analysis system that combines codon usage statistics with Burrows-Wheeler Transform (BWT)-derived features to improve prediction robustness and biological relevance.

ğŸŒ **Live Demo**: [https://codon-usage-tool.onrender.com/](https://codon-usage-tool.onrender.com/)

The system provides:
* Codon ranking for a given amino acid
* Species-level codon usage preference
* Comparison between Codon-only and Codon + BWT models
* Model performance, robustness, and training proof visualizations

---

## ğŸš€ Project Highlights

* ğŸ”¬ **Hybrid feature engineering**: Codon usage + BWT features
* ğŸ“Š **Performance metrics**: Top-1 / Top-2 / Top-3 accuracy, Precision, Recall, F1-score
* ğŸ§ª **Robustness evaluation**: Clean, Noisy, and Missing data testing
* ğŸ§  **Pretrained ML model** (XGBoost-based)
* ğŸŒ **Web interface**: Flask backend + Responsive HTML/CSS/JS frontend
* â˜ï¸ **Deployed on Render**

---

## ğŸ§  Problem Statement

Codon usage bias plays a critical role in gene expression and synthetic biology. Traditional codon analysis relies only on frequency tables and ignores sequence-level patterns.

This project enhances codon analysis by:
* Learning global codon preference patterns
* Incorporating BWT-based sequence features
* Evaluating model robustness under noisy and missing data

---

## ğŸ“Œ Key Features

### Input
* **Amino Acid** (single-letter code, e.g., `L`, `K`)
* **Optional Codon** (RNA format, e.g., `UUA`, `UUU`)

### Output
* Ranked synonymous codons
* Top species associated with selected codon/amino acid
* Accuracy comparison (Codon vs Codon + BWT)
* Model evaluation metrics
* Robustness metrics
* Training proof plots (confusion matrix, accuracy/loss curves, feature correlations)

---

## ğŸ“Š Model Performance Summary

| Model | Top-1 Accuracy |
|-------|----------------|
| Codon Only | 96.91% |
| Codon + BWT | **97.78%** |

âœ” **Improved robustness** âœ” **Stable convergence** âœ” **Minimal accuracy trade-off**

The hybrid **Codon + BWT model** improves Top-1 accuracy from 96.91% to 97.78%, and demonstrates robustness under noisy and missing data. Training plots and confusion matrices are included as evidence of model convergence.

---

## ğŸ› ï¸ Tech Stack

* **Backend**: Flask (Python)
* **Machine Learning**: XGBoost, Scikit-learn
* **Data Processing**: Pandas, NumPy
* **Bioinformatics**: Biopython
* **Frontend**: HTML, CSS, JavaScript (Responsive Design)
* **Deployment**: Render

---

## ğŸ“¦ Installation & Setup (Local)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/RishavRaj625/Codon_Bwt.git
cd Codon_Bwt
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Required Packages

```bash
pip install -r requirements.txt
```

**Or install packages manually:**

```bash
pip install flask flask-cors pandas numpy scikit-learn xgboost joblib biopython
```

> âš ï¸ **Troubleshooting**: If the code is not running in VS Code, please recheck that all the above packages are properly installed. You can verify installation by running:
> ```bash
> pip list
> ```

---

## â–¶ï¸ How to Run Locally

```bash
python app.py
```

Open your browser:

```
http://127.0.0.1:5000
```

---

## ğŸ“ Project Structure

```
Codon_Bwt/
â”‚
â”œâ”€â”€ app.py                              # Flask backend application
â”œâ”€â”€ index.html                          # Main frontend interface
â”œâ”€â”€ codon_usage.csv                     # Codon usage frequency data
â”œâ”€â”€ final_features_with_bwt.csv         # Processed features with BWT
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ README.md                           # Project documentation
â”‚
â”œâ”€â”€ model_outputs/                      # Trained models and metrics
â”‚   â”œâ”€â”€ aa_models_with_bwt.pkl         # Amino acid models
â”‚   â”œâ”€â”€ evaluation_metrics.json         # Model evaluation results
â”‚   â”œâ”€â”€ feature_manifest_with_bwt.json  # Feature configuration
â”‚   â”œâ”€â”€ global_clf_codon_bwt.pkl       # Global classifier
â”‚   â”œâ”€â”€ global_codon_bwt_model.pkl     # Main trained model
â”‚   â”œâ”€â”€ global_le_codon_bwt.pkl        # Label encoder
â”‚   â”œâ”€â”€ label_encoder.pkl               # Label encoder backup
â”‚   â”œâ”€â”€ per_AA_stats_with_bwt.csv      # Per amino acid statistics
â”‚   â””â”€â”€ species_id_map.json             # Species mapping
â”‚
â”œâ”€â”€ static/                             # Training proof visualizations
â”‚   â”œâ”€â”€ Codon_BWT.png
â”‚   â”œâ”€â”€ BWT impact output.png
â”‚   â”œâ”€â”€ confusion matrix output.png
â”‚   â”œâ”€â”€ Feature Correlation Heatmap output.png
â”‚   â”œâ”€â”€ Recall_F1 Score.png
â”‚   â”œâ”€â”€ Residual Dist output.png
â”‚   â”œâ”€â”€ Residuals vs Predictions output.png
â”‚   â”œâ”€â”€ Test data metric output.png
â”‚   â”œâ”€â”€ Training vs test Acc output.png
â”‚   â””â”€â”€ Training vs test loss output.png
â”‚
â”œâ”€â”€ Training_code/                      # Model training notebooks
â”‚   â””â”€â”€ bwt-codon.ipynb                # Complete training pipeline
â”‚
â””â”€â”€ venv/                               # Virtual environment (local)
```

---

## ğŸ¯ Features Breakdown

### Page 1: Hybrid Codon Recommendation System
- Input amino acid and optional codon
- View ranked synonymous codons with ML weights
- See top species using the codon

### Page 2: Model Performance Metrics
- Accuracy comparison between models
- Detailed evaluation metrics (Precision, Recall, F1)
- Robustness evaluation under different data conditions

### Page 3: Training & Evaluation Proof
- 10 comprehensive visualization plots
- Confusion matrix
- Training vs test accuracy/loss curves
- Feature correlation heatmaps
- BWT impact analysis

---

## â˜ï¸ Deployment on Render

* Flask app deployed using **Render Web Service**
* Pretrained model files loaded at runtime
* No retraining during inference
* Static assets served via Flask
* **Live URL**: [https://codon-usage-tool.onrender.com/](https://codon-usage-tool.onrender.com/)

---

## ğŸ”¬ Model Training

The model training pipeline is located in `Training_code/bwt-codon.ipynb`. The notebook includes:

1. **Data preprocessing** - Codon usage frequency extraction
2. **BWT feature engineering** - Sequence-level pattern encoding
3. **Model training** - XGBoost classifier with cross-validation
4. **Evaluation** - Comprehensive metrics and robustness testing
5. **Visualization** - Training proof plots generation

All trained models and metrics are saved to `model_outputs/` directory.

---

## ğŸ“± Responsive Design

The web interface is fully responsive and optimized for:
- ğŸ“± Mobile devices (< 480px)
- ğŸ“± Tablets (481px - 768px)
- ğŸ’» Desktop (> 1200px)
- ğŸ–¥ï¸ Large screens

Features touch-friendly buttons, adaptive layouts, and optimized image viewing.

---

## ğŸ“ Academic Note

* Model evaluation metrics are generated during training
* Inference phase only loads trained results
* Confusion matrix and plots serve as training evidence
* All visualizations are stored in `static/` folder

---

## ğŸ“Œ Future Enhancements

* Multi-codon sequence optimization
* Codon Adaptation Index (CAI) integration
* Organism-specific optimization
* Public REST API for bioinformatics tools
* Real-time codon optimization suggestions

---

## ğŸ‘¨â€ğŸ’» Author

**Rishav Raj**  
Final Year Project â€“ Machine Learning & Bioinformatics

- ğŸŒ GitHub: [https://github.com/RishavRaj625](https://github.com/RishavRaj625)
- ğŸ”— Project Repository: [https://github.com/RishavRaj625/Codon_Bwt](https://github.com/RishavRaj625/Codon_Bwt)
- ğŸš€ Live Demo: [https://codon-usage-tool.onrender.com/](https://codon-usage-tool.onrender.com/)

---

## ğŸ“œ License

This project is intended for **academic and research use**.

---

## ğŸ™ Acknowledgments

Special thanks to mentors and external reviewers for their guidance and feedback on this project.

---

## ğŸ“§ Contact

For questions, suggestions, or collaborations, please reach out through GitHub or the project repository.

---

**â­ If you find this project useful, please consider giving it a star on GitHub!**
